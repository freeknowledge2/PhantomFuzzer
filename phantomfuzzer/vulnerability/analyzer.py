#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Vulnerability analyzer for PhantomFuzzer.

This module provides a factory class for analyzing potential
vulnerabilities in various targets, including files, web applications,
APIs, and network services.
"""

import os
import re
import json
import ipaddress
from pathlib import Path
from typing import Dict, List, Any, Optional, Union, Set, Tuple, Callable
from urllib.parse import urlparse

# Import from phantomfuzzer package
from phantomfuzzer.utils.logging import get_module_logger
from phantomfuzzer.utils.helper import print_info, print_warning, print_error, print_success

# Import vulnerability constants
from phantomfuzzer.vulnerability import (
    # Severity levels
    SEVERITY_CRITICAL, SEVERITY_HIGH, SEVERITY_MEDIUM, SEVERITY_LOW, SEVERITY_INFO,
    
    # Vulnerability categories
    CATEGORY_BROKEN_ACCESS_CONTROL, CATEGORY_CRYPTO_FAILURES, CATEGORY_INJECTION,
    CATEGORY_INSECURE_DESIGN, CATEGORY_SECURITY_MISCONFIG, CATEGORY_VULNERABLE_COMPONENTS,
    CATEGORY_AUTH_FAILURES, CATEGORY_SOFTWARE_DATA_INTEGRITY, CATEGORY_LOGGING_MONITORING,
    CATEGORY_SSRF
)

# Import specialized analyzers
from phantomfuzzer.vulnerability.models import Vulnerability
from phantomfuzzer.vulnerability.file_analyzer import FileAnalyzer
from phantomfuzzer.vulnerability.web_analyzer import WebAnalyzer
from phantomfuzzer.vulnerability.api_analyzer import APIAnalyzer
from phantomfuzzer.vulnerability.network_analyzer import NetworkAnalyzer


class VulnerabilityAnalyzer:
    """Factory class for analyzing vulnerabilities in various targets.
    
    This class detects the target type and delegates the analysis to the
    appropriate specialized analyzer (FileAnalyzer, WebAnalyzer, APIAnalyzer,
    or NetworkAnalyzer).
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """Initialize the vulnerability analyzer factory.
        
        Args:
            config: Optional configuration dictionary.
        """
        self.logger = get_module_logger('vulnerability_analyzer')
        self.config = config or {}
        
        # Initialize vulnerability patterns
        self.patterns = self._init_vulnerability_patterns()
        
        # Initialize ML integration if available
        self.ml_enabled = self.config.get('ml_enabled', False)
        self.ml_integration = None
        
        if self.ml_enabled:
            try:
                from phantomfuzzer.ml import MLIntegration
                self.ml_integration = MLIntegration()
                self.logger.info("ML integration initialized for vulnerability analysis")
                print_info("ML integration initialized for vulnerability analysis")
            except ImportError:
                self.logger.warning("ML integration not available")
                print_warning("ML integration not available for vulnerability analysis")
                self.ml_enabled = False
    
    def analyze(self, target: Union[str, Path], scan_context: Optional[Dict[str, Any]] = None) -> List[Vulnerability]:
        """Analyze a target for vulnerabilities by automatically detecting its type.
        
        Args:
            target: The target to analyze (file path, URL, API endpoint, or network target).
            scan_context: Optional context information about the scan.
        
        Returns:
            A list of detected vulnerabilities.
        """
        # Convert target to string if it's a Path object
        target_str = str(target) if isinstance(target, Path) else target
        
        # Detect target type and delegate to appropriate analyzer
        if isinstance(target, Path) or (isinstance(target_str, str) and Path(target_str).exists()):
            # It's a file
            return self.analyze_file(target, scan_context)
        elif self._is_valid_url(target_str):
            # Check if it's an API or a web application
            if scan_context and scan_context.get('target_type') == 'api':
                return self.analyze_api(target_str, scan_context)
            else:
                return self.analyze_web(target_str, scan_context)
        elif self._is_valid_network_target(target_str):
            # It's a network target
            return self.analyze_network(target_str, scan_context)
        else:
            self.logger.error(f"Unknown target type: {target}")
            print_error(f"Unknown target type: {target}")
            return []
    
    def analyze_file(self, file_path: Union[str, Path], scan_context: Optional[Dict[str, Any]] = None) -> List[Vulnerability]:
        """Analyze a file for vulnerabilities using the FileAnalyzer.
        
        Args:
            file_path: The path to the file to analyze.
            scan_context: Optional context information about the scan.
        
        Returns:
            A list of detected vulnerabilities.
        """
        file_path = Path(file_path) if isinstance(file_path, str) else file_path
        self.logger.info(f"Analyzing file for vulnerabilities: {file_path}")
        print_info(f"Analyzing file for vulnerabilities: {file_path}")
        
        try:
            # Create a FileAnalyzer instance
            file_analyzer = FileAnalyzer(self.config)
            
            # Share vulnerability patterns with the analyzer
            file_analyzer.patterns = self.patterns
            
            # Share ML integration if available
            if self.ml_enabled and self.ml_integration:
                file_analyzer.ml_enabled = True
                file_analyzer.ml_integration = self.ml_integration
            
            # Delegate the analysis to the specialized analyzer
            return file_analyzer.analyze(file_path, scan_context)
        except Exception as e:
            self.logger.error(f"Error analyzing file {file_path}: {str(e)}")
            print_error(f"Error analyzing file {file_path}: {str(e)}")
            return []
    
    def _is_binary_file(self, file_path: Path) -> bool:
        """Check if a file is binary.
        
        Args:
            file_path: The path to the file to check.
        
        Returns:
            True if the file is binary, False otherwise.
        """
        try:
            with open(file_path, 'rb') as f:
                chunk = f.read(1024)
                return b'\0' in chunk
        except Exception:
            return False
    
    def _check_file_permissions(self, file_path: Path, vulnerabilities: List[Vulnerability]) -> None:
        """Check file permissions for security issues.
        
        Args:
            file_path: The path to the file to check.
            vulnerabilities: The list to add detected vulnerabilities to.
        """
        # Check for world-writable files
        try:
            mode = os.stat(file_path).st_mode
            if mode & 0o002:  # World-writable
                vuln = Vulnerability(
                    name=VULN_INSECURE_PERMISSION,
                    description="File has world-writable permissions",
                    severity=SEVERITY_HIGH,
                    location=str(file_path),
                    category=CATEGORY_BROKEN_ACCESS_CONTROL,
                    evidence=f"File mode: {oct(mode)}",
                    remediation="Change file permissions to restrict write access",
                    cwe_id="CWE-732",
                    detection_method="permission_check"
                )
                vulnerabilities.append(vuln)
        except Exception as e:
            self.logger.error(f"Error checking file permissions for {file_path}: {str(e)}")
    
    def _check_sensitive_info(self, file_path: Path, content: str, vulnerabilities: List[Vulnerability]) -> None:
        """Check for sensitive information in file content.
        
        Args:
            file_path: The path to the file being analyzed.
            content: The content of the file.
            vulnerabilities: The list to add detected vulnerabilities to.
        """
        patterns = self.patterns.get('file', {}).get('sensitive_info', {})
        
        for pattern_name, pattern_info in patterns.items():
            matches = re.finditer(pattern_info['pattern'], content)
            for match in matches:
                evidence = match.group(0)
                vuln = Vulnerability(
                    name=VULN_SENSITIVE_INFO,
                    description=f"Found {pattern_name} in file",
                    severity=pattern_info['severity'],
                    location=str(file_path),
                    category=pattern_info.get('category'),
                    evidence=evidence,
                    remediation="Remove sensitive information or use environment variables/secure storage",
                    cwe_id="CWE-312",
                    detection_method="pattern_match",
                    pattern_type=pattern_name,
                    line_number=content[:match.start()].count('\n') + 1
                )
                vulnerabilities.append(vuln)
    
    def _check_code_vulnerabilities(self, file_path: Path, content: str, vulnerabilities: List[Vulnerability]) -> None:
        """Check for code vulnerabilities in file content.
        
        Args:
            file_path: The path to the file being analyzed.
            content: The content of the file.
            vulnerabilities: The list to add detected vulnerabilities to.
        """
        patterns = self.patterns.get('file', {}).get('code_vulnerability', {})
        
        for pattern_name, pattern_info in patterns.items():
            matches = re.finditer(pattern_info['pattern'], content)
            for match in matches:
                evidence = match.group(0)
                vuln = Vulnerability(
                    name=VULN_CODE_VULNERABILITY,
                    description=f"Potential {pattern_name.replace('_', ' ')} vulnerability detected",
                    severity=pattern_info['severity'],
                    location=str(file_path),
                    category=pattern_info.get('category'),
                    evidence=evidence,
                    remediation=f"Review and fix the {pattern_name.replace('_', ' ')} vulnerability",
                    cwe_id=pattern_info.get('cwe_id'),
                    detection_method="pattern_match",
                    pattern_type=pattern_name,
                    line_number=content[:match.start()].count('\n') + 1
                )
                vulnerabilities.append(vuln)
    
    def _analyze_with_ml(self, file_path: Path, content: str, vulnerabilities: List[Vulnerability]) -> None:
        """Use ML to enhance vulnerability detection.
        
        Args:
            file_path: The path to the file being analyzed.
            content: The content of the file.
            vulnerabilities: The list to add detected vulnerabilities to.
        """
        try:
            # This is a placeholder for ML-based analysis
            # In a real implementation, this would use the ML integration
            # to analyze the file content for vulnerabilities
            ml_result = self.ml_integration.detect_file_anomalies(
                file_path=str(file_path)
            )
            
            if ml_result and 'anomalies' in ml_result and ml_result['anomalies']:
                for anomaly in ml_result['anomalies']:
                    confidence = anomaly.get('confidence', 0.7)
                    if confidence >= 0.5:  # Only report if confidence is high enough
                        vuln = Vulnerability(
                            name="ML-Detected Anomaly",
                            description=anomaly.get('description', 'Suspicious code pattern detected by ML'),
                            severity=SEVERITY_MEDIUM,  # Default to medium, can be adjusted based on the anomaly
                            location=str(file_path),
                            evidence=anomaly.get('code_snippet'),
                            detection_method="ml_analysis",
                            confidence=confidence,
                            ml_model=ml_result.get('model_name'),
                            anomaly_type=anomaly.get('type')
                        )
                        vulnerabilities.append(vuln)
        except Exception as e:
            self.logger.error(f"Error in ML analysis for {file_path}: {str(e)}")
            print_error(f"Error in ML analysis for {file_path}: {str(e)}")
    
    def analyze_web(self, target_url: str, scan_context: Optional[Dict[str, Any]] = None) -> List[Vulnerability]:
        """Analyze a web application for vulnerabilities using the WebAnalyzer.
        
        Args:
            target_url: The URL of the web application to analyze.
            scan_context: Optional context information about the scan.
        
        Returns:
            A list of detected vulnerabilities.
        """
        self.logger.info(f"Analyzing web application for vulnerabilities: {target_url}")
        print_info(f"Analyzing web application for vulnerabilities: {target_url}")
        
        # Validate URL
        if not self._is_valid_url(target_url):
            self.logger.warning(f"Invalid URL: {target_url}")
            print_warning(f"Invalid URL: {target_url}")
            return []
        
        try:
            # Create a WebAnalyzer instance
            web_analyzer = WebAnalyzer(self.config)
            
            # Share vulnerability patterns with the analyzer
            web_analyzer.patterns = self.patterns
            
            # Share ML integration if available
            if self.ml_enabled and self.ml_integration:
                web_analyzer.ml_enabled = True
                web_analyzer.ml_integration = self.ml_integration
            
            # Delegate the analysis to the specialized analyzer
            return web_analyzer.analyze(target_url, scan_context)
        except Exception as e:
            self.logger.error(f"Error analyzing web application {target_url}: {str(e)}")
            print_error(f"Error analyzing web application {target_url}: {str(e)}")
            return []
    
    def analyze_api(self, api_url: str, scan_context: Optional[Dict[str, Any]] = None) -> List[Vulnerability]:
        """Analyze an API for vulnerabilities using the APIAnalyzer.
        
        Args:
            api_url: The URL of the API to analyze.
            scan_context: Optional context information about the scan.
        
        Returns:
            A list of detected vulnerabilities.
        """
        self.logger.info(f"Analyzing API for vulnerabilities: {api_url}")
        print_info(f"Analyzing API for vulnerabilities: {api_url}")
        
        # Validate URL
        if not self._is_valid_url(api_url):
            self.logger.warning(f"Invalid API URL: {api_url}")
            print_warning(f"Invalid API URL: {api_url}")
            return []
        
        try:
            # Create an APIAnalyzer instance
            api_analyzer = APIAnalyzer(self.config)
            
            # Share vulnerability patterns with the analyzer
            api_analyzer.patterns = self.patterns
            
            # Share ML integration if available
            if self.ml_enabled and self.ml_integration:
                api_analyzer.ml_enabled = True
                api_analyzer.ml_integration = self.ml_integration
            
            # Delegate the analysis to the specialized analyzer
            return api_analyzer.analyze(api_url, scan_context)
        except Exception as e:
            self.logger.error(f"Error analyzing API {api_url}: {str(e)}")
            print_error(f"Error analyzing API {api_url}: {str(e)}")
            return []
    
    def analyze_network(self, target: str, scan_context: Optional[Dict[str, Any]] = None) -> List[Vulnerability]:
        """Analyze a network target for vulnerabilities using the NetworkAnalyzer.
        
        Args:
            target: The network target to analyze (e.g., IP address, hostname).
            scan_context: Optional context information about the scan.
        
        Returns:
            A list of detected vulnerabilities.
        """
        self.logger.info(f"Analyzing network target for vulnerabilities: {target}")
        print_info(f"Analyzing network target for vulnerabilities: {target}")
        
        # Validate target
        if not self._is_valid_network_target(target):
            self.logger.warning(f"Invalid network target: {target}")
            print_warning(f"Invalid network target: {target}")
            return []
        
        try:
            # Create a NetworkAnalyzer instance
            network_analyzer = NetworkAnalyzer(self.config)
            
            # Share vulnerability patterns with the analyzer
            network_analyzer.patterns = self.patterns
            
            # Share ML integration if available
            if self.ml_enabled and self.ml_integration:
                network_analyzer.ml_enabled = True
                network_analyzer.ml_integration = self.ml_integration
            
            # Delegate the analysis to the specialized analyzer
            return network_analyzer.analyze(target, scan_context)
        except Exception as e:
            self.logger.error(f"Error analyzing network target {target}: {str(e)}")
            print_error(f"Error analyzing network target {target}: {str(e)}")
            return []
    
    def _is_valid_url(self, url: str) -> bool:
        """Check if a URL is valid.
        
        Args:
            url: The URL to check.
        
        Returns:
            True if the URL is valid, False otherwise.
        """
        try:
            result = urlparse(url)
            return all([result.scheme, result.netloc])
        except Exception:
            return False
    
    def _is_valid_network_target(self, target: str) -> bool:
        """Check if a network target is valid.
        
        Args:
            target: The network target to check.
        
        Returns:
            True if the target is valid, False otherwise.
        """
        # Check if it's an IP address
        try:
            ipaddress.ip_address(target)
            return True
        except ValueError:
            pass
        
        # Check if it's a hostname
        if re.match(r'^[a-zA-Z0-9][-a-zA-Z0-9.]*[a-zA-Z0-9]$', target):
            return True
        
        return False
    
    def _init_vulnerability_patterns(self) -> Dict[str, Dict[str, Any]]:
        """Initialize vulnerability patterns for different target types.
        
        Returns:
            A dictionary of vulnerability patterns.
        """
        # This method can be extended with more patterns
        return {
            # File vulnerability patterns
            'file': {
                # Sensitive information patterns
                'sensitive_info': {
                    'api_key': {
                        'pattern': r'(?i)(api[_-]?key|apikey)[\s]*[=:][\s]*["\'](\w+)["\'](\s*;)?',
                        'severity': SEVERITY_HIGH,
                        'category': CATEGORY_CRYPTO_FAILURES
                    },
                    'password': {
                        'pattern': r'(?i)(password|passwd|pwd)[\s]*[=:][\s]*["\'](\w+)["\'](\s*;)?',
                        'severity': SEVERITY_HIGH,
                        'category': CATEGORY_CRYPTO_FAILURES
                    },
                    'private_key': {
                        'pattern': r'-----BEGIN\s+(?:RSA|DSA|EC|OPENSSH)\s+PRIVATE\s+KEY-----',
                        'severity': SEVERITY_CRITICAL,
                        'category': CATEGORY_CRYPTO_FAILURES
                    }
                },
                
                # Code vulnerability patterns
                'code_vulnerability': {
                    'sql_injection': {
                        'pattern': r'(?i)execute\s*\(\s*["\'](\s*SELECT|INSERT|UPDATE|DELETE).*?[\+\.]',
                        'severity': SEVERITY_HIGH,
                        'category': CATEGORY_INJECTION,
                        'cwe_id': 'CWE-89'
                    },
                    'command_injection': {
                        'pattern': r'(?i)(system|exec|popen|subprocess\.call)\s*\(\s*["\'](.*?)[\+\.][\w\s]*["\'\)]',
                        'severity': SEVERITY_HIGH,
                        'category': CATEGORY_INJECTION,
                        'cwe_id': 'CWE-78'
                    },
                    'path_traversal': {
                        'pattern': r'(?i)(open|file|read|write)\s*\(\s*["\'](.*?)[\+\.][\w\s]*["\'\)]',
                        'severity': SEVERITY_MEDIUM,
                        'category': CATEGORY_BROKEN_ACCESS_CONTROL,
                        'cwe_id': 'CWE-22'
                    }
                }
            },
            
            # Web vulnerability patterns
            'web': {
                # Web-specific patterns
                'injection': {
                    'xss': {
                        'pattern': r'<script>.*?</script>',
                        'severity': SEVERITY_HIGH,
                        'category': CATEGORY_INJECTION,
                        'cwe_id': 'CWE-79'
                    },
                    'sql_injection': {
                        'pattern': r'(?i)\b(union|select|from|where|drop|insert|delete)\b.*?\b(union|select|from|where|drop|insert|delete)\b',
                        'severity': SEVERITY_HIGH,
                        'category': CATEGORY_INJECTION,
                        'cwe_id': 'CWE-89'
                    }
                }
            },
            
            # API vulnerability patterns
            'api': {
                # API-specific patterns
                'authentication': {
                    'missing_auth': {
                        'pattern': r'',  # This would be implemented with actual API testing
                        'severity': SEVERITY_HIGH,
                        'category': CATEGORY_AUTH_FAILURES,
                        'cwe_id': 'CWE-306'
                    }
                }
            },
            
            # Network vulnerability patterns
            'network': {
                # Network-specific patterns
                'open_ports': {
                    'pattern': r'',  # This would be implemented with actual network scanning
                    'severity': SEVERITY_MEDIUM,
                    'category': CATEGORY_SECURITY_MISCONFIG
                }
            }
        }