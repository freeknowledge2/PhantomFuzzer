#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
File vulnerability analyzer for PhantomFuzzer.

This module provides a specialized analyzer for detecting vulnerabilities in files.
"""

import os
import re
import stat
from pathlib import Path
from typing import Dict, List, Any, Optional, Union, Set

# Import from phantomfuzzer package
from phantomfuzzer.utils.logging import get_module_logger
from phantomfuzzer.utils.helper import print_info, print_warning, print_error

# Import from vulnerability module
from phantomfuzzer.vulnerability.base_analyzer import BaseAnalyzer
from phantomfuzzer.vulnerability.models import Vulnerability

# Import vulnerability constants
from phantomfuzzer.vulnerability import (
    # Severity levels
    SEVERITY_CRITICAL, SEVERITY_HIGH, SEVERITY_MEDIUM, SEVERITY_LOW, SEVERITY_INFO,
    
    # Vulnerability categories
    CATEGORY_CRYPTO_FAILURES, CATEGORY_INJECTION, CATEGORY_INSECURE_DESIGN,
    CATEGORY_SECURITY_MISCONFIG, CATEGORY_VULNERABLE_COMPONENTS,
    
    # Vulnerability types
    VULN_SENSITIVE_INFO, VULN_CODE_VULNERABILITY, VULN_INSECURE_PERMISSION
)


class FileAnalyzer(BaseAnalyzer):
    """Specialized analyzer for detecting vulnerabilities in files."""
    
    def _load_patterns(self) -> Dict[str, Any]:
        """Load vulnerability patterns for file analysis.
        
        Returns:
            A dictionary of vulnerability patterns.
        """
        # Sensitive information patterns
        sensitive_info_patterns = {
            'api_key': {
                'pattern': r'(?i)(api[_-]?key|apikey|access[_-]?key|secret[_-]?key)["\']?\s*(?::|=|=>)\s*["\']([a-zA-Z0-9]{16,})["\']\s*',
                'description': 'API key or secret key detected',
                'severity': SEVERITY_HIGH,
                'category': CATEGORY_CRYPTO_FAILURES,
                'remediation': 'Store API keys in environment variables or a secure vault, not in source code.'
            },
            'password': {
                'pattern': r'(?i)(password|passwd|pwd)["\']?\s*(?::|=|=>)\s*["\']([^"\']{8,})["\']\s*',
                'description': 'Hardcoded password detected',
                'severity': SEVERITY_HIGH,
                'category': CATEGORY_CRYPTO_FAILURES,
                'remediation': 'Store passwords in environment variables or a secure vault, not in source code.'
            },
            'private_key': {
                'pattern': r'-----BEGIN (?:RSA|DSA|EC|OPENSSH) PRIVATE KEY-----',
                'description': 'Private key detected',
                'severity': SEVERITY_CRITICAL,
                'category': CATEGORY_CRYPTO_FAILURES,
                'remediation': 'Never store private keys in source code. Use a secure key management system.'
            },
            'aws_credentials': {
                'pattern': r'(?i)aws[_-]?(?:access[_-]?key|secret[_-]?key|account[_-]?id)["\']?\s*(?::|=|=>)\s*["\']([^"\']{16,})["\']\s*',
                'description': 'AWS credentials detected',
                'severity': SEVERITY_CRITICAL,
                'category': CATEGORY_CRYPTO_FAILURES,
                'remediation': 'Use AWS IAM roles or environment variables instead of hardcoded credentials.'
            },
            'connection_string': {
                'pattern': r'(?i)(?:connection[_-]?string|connstr)["\']?\s*(?::|=|=>)\s*["\']([^"\']{16,})["\']\s*',
                'description': 'Database connection string detected',
                'severity': SEVERITY_HIGH,
                'category': CATEGORY_CRYPTO_FAILURES,
                'remediation': 'Store connection strings in environment variables or a secure configuration system.'
            }
        }
        
        # Code vulnerability patterns
        code_vulnerability_patterns = {
            'sql_injection': {
                'pattern': r'(?i)(?:execute|exec|query)\s*\(\s*["\']SELECT\s+.*\+\s*.*["\']',
                'description': 'Potential SQL injection vulnerability',
                'severity': SEVERITY_HIGH,
                'category': CATEGORY_INJECTION,
                'remediation': 'Use parameterized queries or prepared statements instead of string concatenation.'
            },
            'command_injection': {
                'pattern': r'(?i)(?:system|exec|popen|subprocess\.call|subprocess\.Popen|os\.system|shell_exec)\s*\(\s*["\'].*\+\s*.*["\']',
                'description': 'Potential command injection vulnerability',
                'severity': SEVERITY_CRITICAL,
                'category': CATEGORY_INJECTION,
                'remediation': 'Avoid using shell commands with user input. If necessary, use proper input validation and sanitization.'
            },
            'path_traversal': {
                'pattern': r'(?i)(?:open|file|read|write)\s*\(\s*["\'].*\+\s*.*["\']',
                'description': 'Potential path traversal vulnerability',
                'severity': SEVERITY_HIGH,
                'category': CATEGORY_INJECTION,
                'remediation': 'Use safe path handling functions and validate user input before using it in file operations.'
            },
            'insecure_deserialization': {
                'pattern': r'(?i)(?:pickle\.loads|yaml\.load|marshal\.loads|json\.loads)\s*\(\s*.*\)',
                'description': 'Potential insecure deserialization',
                'severity': SEVERITY_HIGH,
                'category': CATEGORY_INSECURE_DESIGN,
                'remediation': 'Use safe alternatives like yaml.safe_load() or json.loads() with proper validation.'
            },
            'weak_crypto': {
                'pattern': r'(?i)(?:md5|sha1|des|rc4|blowfish)(?:\.|_)',
                'description': 'Weak cryptographic algorithm detected',
                'severity': SEVERITY_MEDIUM,
                'category': CATEGORY_CRYPTO_FAILURES,
                'remediation': 'Use strong cryptographic algorithms like AES-256, SHA-256, or better.'
            }
        }
        
        return {
            'sensitive_info': sensitive_info_patterns,
            'code_vulnerabilities': code_vulnerability_patterns
        }
    
    def analyze(self, target: Union[str, Path], scan_context: Optional[Dict[str, Any]] = None) -> List[Vulnerability]:
        """Analyze a file for vulnerabilities.
        
        Args:
            target: The path to the file to analyze.
            scan_context: Optional context information about the scan.
        
        Returns:
            A list of detected vulnerabilities.
        """
        # Convert string path to Path object if necessary
        file_path = Path(target) if isinstance(target, str) else target
        
        # Check if file exists
        if not file_path.exists():
            self.logger.error(f"File not found: {file_path}")
            print_error(f"File not found: {file_path}")
            return []
        
        # Check if file is a regular file
        if not file_path.is_file():
            self.logger.error(f"Not a regular file: {file_path}")
            print_error(f"Not a regular file: {file_path}")
            return []
        
        # Initialize list to store detected vulnerabilities
        vulnerabilities = []
        
        try:
            # Check file permissions
            self._check_file_permissions(file_path, vulnerabilities)
            
            # Skip binary files
            if self._is_binary_file(file_path):
                self.logger.info(f"Skipping binary file: {file_path}")
                return vulnerabilities
            
            # Read file content
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            # Check for sensitive information
            self._check_sensitive_info(file_path, content, vulnerabilities)
            
            # Check for code vulnerabilities
            self._check_code_vulnerabilities(file_path, content, vulnerabilities)
            
            # Use ML for enhanced detection if enabled
            if self.ml_enabled and self.ml_integration:
                self._analyze_with_ml(file_path, content, vulnerabilities)
            
            return vulnerabilities
            
        except Exception as e:
            self._handle_exception(e, f"Error analyzing file {file_path}")
            return vulnerabilities
    
    def _is_binary_file(self, file_path: Path) -> bool:
        """Check if a file is binary.
        
        Args:
            file_path: The path to the file to check.
        
        Returns:
            True if the file is binary, False otherwise.
        """
        # Check file extension first
        binary_extensions = {'.exe', '.dll', '.so', '.dylib', '.bin', '.dat', '.img', 
                             '.iso', '.zip', '.tar', '.gz', '.rar', '.7z', '.jar', 
                             '.war', '.ear', '.class', '.pyc', '.pyd', '.pyo', 
                             '.o', '.obj', '.lib', '.a', '.pdf', '.jpg', '.jpeg', 
                             '.png', '.gif', '.bmp', '.ico', '.tif', '.tiff', 
                             '.mp3', '.mp4', '.avi', '.mov', '.wmv', '.flv', 
                             '.wav', '.ogg', '.mkv', '.db', '.sqlite', '.mdb'}
        
        if file_path.suffix.lower() in binary_extensions:
            return True
        
        # Check content
        try:
            with open(file_path, 'rb') as f:
                chunk = f.read(1024)
                if b'\x00' in chunk:
                    return True
                
                # Try to decode as text
                try:
                    chunk.decode('utf-8')
                    return False
                except UnicodeDecodeError:
                    return True
        except Exception:
            # If we can't read the file, assume it's binary
            return True
    
    def _check_file_permissions(self, file_path: Path, vulnerabilities: List[Vulnerability]) -> None:
        """Check file permissions for security issues.
        
        Args:
            file_path: The path to the file to check.
            vulnerabilities: The list to add detected vulnerabilities to.
        """
        try:
            # Get file stats
            file_stat = file_path.stat()
            
            # Check for world-writable permissions
            if file_stat.st_mode & stat.S_IWOTH:
                vulnerabilities.append(Vulnerability(
                    name=VULN_INSECURE_PERMISSION,
                    description="File is world-writable, which may allow unauthorized modification",
                    severity=SEVERITY_HIGH,
                    location=str(file_path),
                    category=CATEGORY_SECURITY_MISCONFIG,
                    evidence=f"Permission mode: {oct(file_stat.st_mode)}",
                    remediation="Change file permissions to restrict write access to owner and group only",
                    detection_method="permission_check"
                ))
            
            # Check for world-executable script files
            if (file_stat.st_mode & stat.S_IXOTH) and file_path.suffix in {'.sh', '.bash', '.py', '.pl', '.rb'}:
                vulnerabilities.append(Vulnerability(
                    name=VULN_INSECURE_PERMISSION,
                    description="Script file is world-executable, which may allow unauthorized execution",
                    severity=SEVERITY_MEDIUM,
                    location=str(file_path),
                    category=CATEGORY_SECURITY_MISCONFIG,
                    evidence=f"Permission mode: {oct(file_stat.st_mode)}",
                    remediation="Change file permissions to restrict execute access to owner and group only",
                    detection_method="permission_check"
                ))
        except Exception as e:
            self._handle_exception(e, f"Error checking file permissions for {file_path}")
    
    def _check_sensitive_info(self, file_path: Path, content: str, vulnerabilities: List[Vulnerability]) -> None:
        """Check for sensitive information in file content.
        
        Args:
            file_path: The path to the file being analyzed.
            content: The content of the file.
            vulnerabilities: The list to add detected vulnerabilities to.
        """
        try:
            for name, pattern_info in self.patterns['sensitive_info'].items():
                matches = re.finditer(pattern_info['pattern'], content)
                for match in matches:
                    # Extract the matched text
                    evidence = match.group(0)
                    
                    # Create a vulnerability
                    vulnerabilities.append(Vulnerability(
                        name=VULN_SENSITIVE_INFO,
                        description=pattern_info['description'],
                        severity=pattern_info['severity'],
                        location=f"{file_path}:{content[:match.start()].count(os.linesep) + 1}",
                        category=pattern_info['category'],
                        evidence=evidence,
                        remediation=pattern_info['remediation'],
                        detection_method="pattern_matching"
                    ))
        except Exception as e:
            self._handle_exception(e, f"Error checking sensitive information in {file_path}")
    
    def _check_code_vulnerabilities(self, file_path: Path, content: str, vulnerabilities: List[Vulnerability]) -> None:
        """Check for code vulnerabilities in file content.
        
        Args:
            file_path: The path to the file being analyzed.
            content: The content of the file.
            vulnerabilities: The list to add detected vulnerabilities to.
        """
        try:
            for name, pattern_info in self.patterns['code_vulnerabilities'].items():
                matches = re.finditer(pattern_info['pattern'], content)
                for match in matches:
                    # Extract the matched text
                    evidence = match.group(0)
                    
                    # Create a vulnerability
                    vulnerabilities.append(Vulnerability(
                        name=VULN_CODE_VULNERABILITY,
                        description=pattern_info['description'],
                        severity=pattern_info['severity'],
                        location=f"{file_path}:{content[:match.start()].count(os.linesep) + 1}",
                        category=pattern_info['category'],
                        evidence=evidence,
                        remediation=pattern_info['remediation'],
                        detection_method="pattern_matching"
                    ))
        except Exception as e:
            self._handle_exception(e, f"Error checking code vulnerabilities in {file_path}")
    
    def _analyze_with_ml(self, file_path: Path, content: str, vulnerabilities: List[Vulnerability]) -> None:
        """Use ML to enhance vulnerability detection.
        
        Args:
            file_path: The path to the file being analyzed.
            content: The content of the file.
            vulnerabilities: The list to add detected vulnerabilities to.
        """
        try:
            if self.ml_integration:
                # Get ML predictions
                ml_vulnerabilities = self.ml_integration.analyze_code(content, str(file_path))
                
                # Add ML-detected vulnerabilities to the list
                for vuln in ml_vulnerabilities:
                    vulnerabilities.append(Vulnerability(
                        name=vuln['name'],
                        description=vuln['description'],
                        severity=vuln['severity'],
                        location=f"{file_path}:{vuln['line_number']}",
                        category=vuln.get('category'),
                        evidence=vuln.get('evidence'),
                        remediation=vuln.get('remediation'),
                        detection_method="machine_learning",
                        confidence=vuln.get('confidence', 0.8)
                    ))
        except Exception as e:
            self._handle_exception(e, f"Error during ML analysis of {file_path}")
